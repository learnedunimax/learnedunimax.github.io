<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" /> -->
<!--   <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LearnedUniMax</title>
  <!-- <link rel="icon" type="image/x-icon" href="static/images/favicon.ico"> -->
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<style> 
.video-container {
  position: relative;
  padding-bottom: 56.25%; /* 16:9 ratio */
  height: 0;
  overflow: hidden;
  width: 100%;
}

.video-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
}

</style>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Learning Uniformly Distributed Embedding Clusters of Stylistic Skills for Physically Simulated Characters</h1>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h1 class="subtitle has-text" >ðŸ”Š Turn on the sound for a better experience.</h1>
      <div class="video-container">
        <iframe 
          src="https://www.youtube.com/embed/FxWnMljiNyg?autoplay=1&mute=1&cc_load_policy=1&hl=en"
          title="YouTube video player"
          frameborder="0"
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
          allowfullscreen>
        </iframe>
      </div>
      <br>
      <h2 class="subtitle has-text-centered">
        Main Video: Our controller not only generates high-quality, diverse motions covering the entire dataset but also achieves superior controllability, serving as a cornerstone for diverse applications.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
Learning natural and diverse behaviors from human motion datasets remains a significant challenge in physics-based character control. Existing conditional adversarial models often suffer from tight and biased embedding distributions where embeddings from the same motion are closely grouped in a small area and shorter motions occupy even less space. Our empirical observations indicate this limits the representational capacity and diversity under each skill. An ideal latent space should be maximally packed by all motionâ€™s embedding clusters. Although methods that employ separate embedding space for each motion mitigate this limitation to some extent, introducing a hybrid discrete-continuous embedding space imposes a huge exploration burden on the high-level policy. To address the above limitations, we propose a versatile skill-conditioned controller that learns diverse skills with expressive variations. Our approach leverages the Neural Collapse phenomenon, a natural outcome of the classification-based encoder, to uniformly distributed cluster centers. We additionally propose a novel Embedding Expansion technique to form stylistic embedding clusters for diverse skills that are uniformly distributed on a hypersphere, maximizing the representational area occupied by each skill and minimizing unmapped regions. This maximally packed and uniformly distributed embedding space ensures that embeddings within the same cluster generate behaviors conforming to the characteristics of the corresponding motion clips, yet exhibiting noticeable variations within each cluster. Compared to existing methods, experimental results demonstrate that our controller not only generates high-quality, diverse motions covering the entire dataset but also achieves superior controllability, motion coverage, and diversity under each skill. Both qualitative and quantitative results confirm these traits, enabling our controller to be applied to a wide range of downstream tasks and serving as a cornerstone for diverse applications.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-small">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Pipeline</h2>
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <img src="static/images/pipeline.png" alt="Recovering the Pre-Fine-Tuning Weight of an Aligned Mistral 7B" class="blend-img-background center-image"/>
            <p>
  Our method uses a unit hypersphere as the embedding space to feature uniformly distributed embedding clusters for each skill. We first employ a classification-based encoder to distribute motion features uniformly on a high-dimensional sphere, then apply conditional imitation learning with the Embedding Expansion technique to form a stylistic skill embedding cluster for each skill, achieving a maximally packed and uniformly distributed space
          </p>
        </div>
        </div>
        
      </div>
    </div>
  </div>
 </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered" style="font-size:150%">1. Learning Uniformly Distributed Cluster Centers with Neural Collapse</h2>
      <div class="item item-video4" style="margin-top:-1.5%">
        <div class="item has-text-centered">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/o_NC.mp4"
            type="video/mp4">
          </video>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered" style="font-size:150%">2. Conditional Adversarial Imitation Learning with Embedding Expansion</h2>
      <div class="item item-video4" style="margin-top:-1.5%">
        <div class="item has-text-centered">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/o_EE.mp4"
            type="video/mp4">
          </video>

        </div>
      </div>
    </div>
  </div>
</section>


<!--<section class="hero is-small is-light">-->
<!--  <div class="hero-body">-->
<!--    <div class="container">-->
<!--      <div id="results-carousel" class="carousel results-carousel">-->
<!--        <div class="item item-8">-->
<!--          <video poster="" id="8" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/complete_8.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-29">-->
<!--          <video poster="" id="29" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/complete_29.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-13">-->
<!--          <video poster="" id="13" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/complete_13.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        <div class="item item-9">-->
<!--          <video poster="" id="9" autoplay controls muted loop playsinline height="100%">-->
<!--            <source src="./static/videos/complete_9.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        </div>-->
<!--          Our controller not only learns a diverse repertoire of motor skills from reference motions to synthesize  natural strategies in complex downstream tasks but also guarantee the execution of full movements, such as kinds of combos in video games, to clearly convey motion intentions.-->
<!--          </p>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</section>-->






  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
